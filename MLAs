## Data processing for MLAs

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

file_path = "SraRunTable.txt"

metadata = pd.read_csv(file_path, delimiter=",")
abundance = pd.read_csv('relative_abundance_all.csv')

metadata = metadata[['Run', 'Sample Name', 'Organism', 'Collection_Date', 'sample_title', 'Description', 'env_biome', 'env_feature', 'env_material', 'geo_loc_name', 'HOST', 'Lat_Lon', 'samp_collect_device', 'samp_store_temp', 'lib_const_meth', 'Target_Gene', 'target_subfragment', 'PCR_primers', 'pcr_cond', 'seq_methods', 'seq_qual_check', 'chimera_check', 'fit_result', 'Diagnosis', 'cancer_stage', 'Hx_Prev', 'Hx_of_Polyps', 'Hx_Fam_CRC', 'Age', 'gender', 'Smoke', 'Diabetic', 'Height', 'Weight', 'BMI', 'White', 'Native', 'Black', 'pacific', 'Asian', 'Other', 'Ethnic', 'NSAID', 'Abx', 'Diabetes_Med']]

print(f"the shape of the meta data is: {metadata.shape}")
print(f"the shape of the abundance data is: {abundance.shape}")

## Remove duplicate values over the patients (Sample Name)
# Remove duplicates from metadata DataFrame
metadata = metadata.drop_duplicates(subset='Sample Name')

# Remove corresponding rows from abundance DataFrame
abundance = abundance[abundance['index'].isin(metadata['Run'])]

# Reset the index of the two datasets
metadata1 = metadata.reset_index(drop=True)
abundance = abundance.reset_index(drop=True)

print(f"The shape of the metadata is: {metadata1.shape}")
print(f"The shape of the abundance data is: {abundance.shape}")


columns_of_interest= ['index', 'd__Bacteria;p__Bacteroidota;c__Bacteroidia;o__Bacteroidales;f__Rikenellaceae',
                     'd__Archaea;p__Euryarchaeota;c__Methanobacteria;o__Methanobacteriales;f__Methanobacteriaceae',
                     'd__Bacteria;p__Firmicutes;c__Negativicutes;o__Acidaminococcales;f__Acidaminococcaceae',
                     'd__Bacteria;p__Actinobacteriota;c__Coriobacteriia;o__Coriobacteriales;f__Coriobacteriaceae',
                     'd__Bacteria;p__Proteobacteria;c__Gammaproteobacteria;o__Pasteurellales;f__Pasteurellaceae',
                     'd__Bacteria;p__Bacteroidota;c__Bacteroidia;o__Bacteroidales;f__Marinifilaceae',
                     'd__Bacteria;p__Desulfobacterota;c__Desulfovibrionia;o__Desulfovibrionales;f__Desulfovibrionaceae',
                     'd__Bacteria;p__Bacteroidota;c__Bacteroidia;o__Bacteroidales;f__Barnesiellaceae',
                     'd__Bacteria;p__Actinobacteriota;c__Coriobacteriia;o__Coriobacteriales;f__Eggerthellaceae',
                     'd__Bacteria;p__Bacteroidota;c__Bacteroidia;o__Bacteroidales;f__Porphyromonadaceae',
                     'd__Bacteria;p__Fusobacteriota;c__Fusobacteriia;o__Fusobacteriales;f__Fusobacteriaceae',
                     'd__Bacteria;p__Firmicutes;c__Clostridia;o__Peptococcales;f__Peptococcaceae',
                     'd__Bacteria;p__Proteobacteria;c__Gammaproteobacteria;o__Burkholderiales;f__Neisseriaceae',
                     'd__Bacteria;p__Cyanobacteria;c__Vampirivibrionia;o__Gastranaerophilales;f__Gastranaerophilales',
                     'd__Bacteria;p__Firmicutes;c__Clostridia;o__Peptostreptococcales-Tissierellales;f__Peptostreptococcales-Tissierellales',
                     'd__Bacteria;p__Firmicutes;c__Bacilli;o__Lactobacillales;f__Leuconostocaceae',
                     'd__Bacteria;p__Firmicutes;c__Bacilli;o__Staphylococcales;f__Gemellaceae',
                     'd__Bacteria;p__Firmicutes;c__Clostridia;o__Oscillospirales;f__Oscillospirales',
                     'd__Bacteria;p__Campilobacterota;c__Campylobacteria;o__Campylobacterales;f__Campylobacteraceae',
                     'd__Bacteria;p__Verrucomicrobiota;c__Lentisphaeria;o__Victivallales;f__Victivallaceae',
                     'd__Bacteria;p__Elusimicrobiota;c__Elusimicrobia;o__Elusimicrobiales;f__Elusimicrobiaceae',
                     'd__Bacteria;p__Fusobacteriota;c__Fusobacteriia;o__Fusobacteriales;f__Leptotrichiaceae',
                     'd__Bacteria;p__Bacteroidota;c__Bacteroidia;o__Flavobacteriales;f__Weeksellaceae']
abundance = abundance[columns_of_interest]
abundance.rename(columns = {'index':'Run'}, inplace = True)


## Merging two data frames
metadata = pd.merge(metadata1, abundance, on='Run')

metadata.drop('Run', axis=1, inplace=True)
metadata = metadata.drop('fit_result', axis=1)

# Let's take a look and visualize the percentage of nan values, unique values and the type of our features
from tabulate import tabulate
stats = []
for col in metadata.columns:
    stats.append((col, metadata[col].nunique(), metadata[col].isnull().sum() * 100 / metadata.shape[0], metadata[col].dtype))
    stats_metadata = pd.DataFrame(stats, columns=['Feature', 'Unique_values', '% MissingValues', 'type'])
    metadata_ = stats_metadata.sort_values('% MissingValues', ascending=False)
print(tabulate(metadata_, headers = 'keys', tablefmt = 'psql'))

metadata.drop(columns = ["Collection_Date" ,"Lat_Lon", "cancer_stage","Organism" , "samp_collect_device", "lib_const_meth", "Target_Gene", "target_subfragment", "PCR_primers", "pcr_cond", "seq_methods", "seq_qual_check", "chimera_check"],axis=1, inplace=True)


## Lets take a look on the columns with 1.01% of missing values and decide how to deal with each one
percent1 = ["Hx_Fam_CRC","Age", "gender", "Smoke", "Diabetic", "Height", "Weight", "Native", "White", "Black", "pacific", "Asian", "Other", "Ethnic", "NSAID", "Abx", "Hx_Prev", "Diabetes_Med",   "env_feature", "geo_loc_name", "HOST"]


for i in percent1:
  print(metadata[i].sample(4))
  print(f"unique values {metadata[i].unique()}")
  print('------------------------------------')
  
  
 
 ## After visualizing the sample of columns with 1% missing values and their unique values, several observations can be made. The columns in question are 'BMI', 'Native', 'Pacific', 'Other', 'Ethnic', env_feature, 'geo_loc_name', '*host'. Among these columns, 'Native', 'Pacific', 'Other', 'Ethnic', and '*geo_loc_name' contain either a single unique value or a high proportion of missing values. These columns do not provide substantial variation or information Therefore, removing them from the dataset would not result in a significant loss of valuable information.

metadata = metadata.drop(columns = ['BMI', 'Native', 'pacific' ,'Other' ,'Ethnic',  'geo_loc_name' , 'HOST' ,'env_feature'], axis = 1)


## KNN Imputation of the missing data
columns_to_convert = ['Weight', 'Height' ]
# Convert columns to int type
metadata['Height'].replace('missing', np.nan, inplace=True)
metadata['Weight'].replace('missing', np.nan, inplace=True)
metadata[columns_to_convert] = metadata[columns_to_convert].astype(float)

from pandas.io.formats.style import Subset
from sklearn.impute import KNNImputer
numerical_columns = metadata.select_dtypes(include=np.number).columns
imputed_metadata = metadata.copy()
imputer = KNNImputer(n_neighbors=5)
imputed_metadata[numerical_columns] = imputer.fit_transform(imputed_metadata[numerical_columns])
imputed_metadata.dropna(subset='gender', inplace =True)

imputed_metadata.isna().sum()

from tabulate import tabulate
stats = []
for col in imputed_metadata.columns:
    stats.append((col, imputed_metadata[col].nunique(), imputed_metadata[col].isnull().sum() * 100 / imputed_metadata.shape[0], imputed_metadata[col].dtype))
    stats_metadata = pd.DataFrame(stats, columns=['Feature', 'Unique_values', '% MissingValues', 'type'])
    metadata_ = stats_metadata.sort_values('% MissingValues', ascending=False)
print(tabulate(metadata_, headers = 'keys', tablefmt = 'psql'))

# We can eliminate inconsistent columns and irrelevant columns like "*sample_name" and "sample_title" from the dataset.</br>
Also it turned out after removing the missing values from our target variable, we have discovered that certain columns now contain only a single constant value. Therefore, it is necessary to eliminate these columns from our dataset.
Concerned columns: 'samp_store_temp', '*env_material', '*env_biome', 'description'

imputed_metadata = imputed_metadata.drop(columns = ['samp_store_temp', 'env_material', 'env_biome', 'Description', 'Sample Name' ,'sample_title'], axis=1)

metadata2 = imputed_metadata.replace('adv Adenoma', 'Adenoma').replace('High Risk Normal', 'Adenoma')
metadata2 = metadata2[metadata2['Diagnosis'].astype(str)!='nan']
metadata2['Diagnosis'].unique()

imputed_metadata['Diagnosis'] = metadata2['Diagnosis']

imputed_metadata['Diagnosis'].unique()

plt.figure(figsize= (30,20))
sns.heatmap(imputed_metadata[numerical_columns].corr(),annot=True)
plt.show()


labels = ['Adenoma', 'Normal', 'Cancer']
diagnosis_counts = imputed_metadata['Diagnosis'].value_counts()
count = [np.round(diagnosis_counts[label] / imputed_metadata.shape[0], 2) for label in labels]

plt.style.use('ggplot')
plt.figure(figsize=(11, 6))
plt.title('Disease Status Distribution')
plt.pie(x=count, labels=labels, autopct='%.2f%%', startangle=90)
plt.axis('equal')
plt.legend(loc='upper left')

# Donut
circle = plt.Circle(xy=(0, 0), radius=0.75, facecolor='white')
plt.gca().add_artist(circle)

plt.show()


## Encoding Categorical variables
imputed_metadata['gender'] = imputed_metadata['gender'].map({'male': 1, 'female':0})


## Modelling
import plotly.graph_objects as go
from sklearn.metrics import classification_report

def plot_classification_report(target_test, predictions):
    # Compute classification report
    cr = classification_report(target_test, predictions, output_dict=True)

    # Prepare the metric names and values
    metric_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score']
    metric_values = [cr['accuracy'], cr['macro avg']['precision'], cr['macro avg']['recall'], cr['macro avg']['f1-score']]

    # Create classification report table figure
    table_figure = go.Figure(data=[go.Table(
        header=dict(values=["Metric", "Score"],
                    line_color='#a6611a',
                    fill_color='#018571',
                    font=dict(color='white')),
        cells=dict(values=[metric_names, metric_values],
                   line_color='#a6611a',
                   fill=dict(color=['#80cdc1', '#00FFFF', '#90EE90', '#c27d7f']))
    )])

    # Set table style
    table_figure.update_layout(
        title="Classification Report",
        font=dict(size=12),
        width=500,
        height=300
    )

    # Show the table figure
    table_figure.show()

    # Return the metrics as a list
    return metric_values


from sklearn.model_selection import (train_test_split, cross_val_score, cross_validate,GridSearchCV )
# Train/test split :
X = imputed_metadata.drop('Diagnosis', axis=1)
y = imputed_metadata['Diagnosis']
data_train, data_test, target_train, target_test = train_test_split(
    X, y, random_state=101
)

print(
    f"The training dataset contains {data_train.shape[0]} samples and "
    f"{data_train.shape[1]} features"
)
print(
    f"The testing dataset contains {data_test.shape[0]} samples and "
    f"{data_test.shape[1]} features"
)


from sklearn.metrics import (confusion_matrix, accuracy_score,
                             f1_score, roc_auc_score, precision_score,
                             recall_score, roc_curve, brier_score_loss,
                             precision_recall_curve, log_loss)
from plotly.subplots import make_subplots


my_colors_code = ['#018571', '#80cdc1', '#metadatac27d', '#a6611a']
COLOR_PALETTE = {
    "primary": "#018571",
    "secondary": '#80cdc1',
    "muted": "#a6611a"
}



##Random Forest
from sklearn.ensemble import RandomForestClassifier
from sklearn.experimental import enable_halving_search_cv
from sklearn.model_selection import HalvingGridSearchCV

# Grid Search
param_grid = {'max_depth': [3, 5, 10],
              'min_samples_split': [2, 5, 10]}

base_estimator = RandomForestClassifier(random_state=0, n_estimators=100)  # Corrected argument passing
sh = HalvingGridSearchCV(base_estimator, param_grid, cv=10, factor=2, min_resources=10, max_resources=60).fit(data_train, target_train)

sh.best_estimator_


scores_rf = plot_classification_report(target_test, sh.predict(data_test))

import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
from matplotlib.backends.backend_pdf import PdfPages

def plot_confusion_matrix(target_test, predictions, labels):
    # Compute confusion matrix
    cm = confusion_matrix(target_test, predictions)

    # Normalize the confusion matrix
    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]

    # Plot the confusion matrix
    plt.figure(figsize=(8, 6))
    plt.imshow(cm_normalized, interpolation='nearest', cmap=plt.cm.Blues)
    plt.title('Confusion Matrix')
    plt.colorbar()
    tick_marks = np.arange(len(labels))
    plt.xticks(tick_marks, labels, rotation=45)
    plt.yticks(tick_marks, labels)
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')

    # Add text inside the plot
    thresh = cm_normalized.max() / 2.
    for i in range(cm_normalized.shape[0]):
        for j in range(cm_normalized.shape[1]):
            plt.text(j, i, format(cm_normalized[i, j], '.2f'),
                     ha="center", va="center",
                     color="white" if cm_normalized[i, j] > thresh else "black")

    # Save the plot to a PDF file
    pdf_file = "confusion_matrix.pdf"
    with PdfPages(pdf_file) as pdf:
        pdf.savefig()

    # Show the plot
    plt.tight_layout()
    plt.show()

# Example usage
labels = ['Normal', 'Adenoma', 'Cancer']
predictions = model.predict(data_test)
plot_confusion_matrix(target_test, predictions, labels)

print("Confusion matrix saved as:", pdf_file)



##XGBoost
from xgboost import XGBClassifier
import time

start = time.time()

from sklearn.preprocessing import LabelEncoder

# Create an instance of LabelEncoder
label_encoder = LabelEncoder()

# Fit label encoder on the target variable and transform the labels
target_train_encoded = label_encoder.fit_transform(target_train)

# Train the XGBClassifier
XGB_model = XGBClassifier(random_state=101, booster='gbtree', min_child_weight=23, max_depth=6)
XGB_model.fit(data_train, target_train_encoded)
elapsed_time_2 = time.time() - start

print(
    f"The model {XGB_model.__class__.__name__} was trained in "
    f"{elapsed_time_2:.3f} seconds"
)


from sklearn.preprocessing import LabelEncoder

# Create an instance of LabelEncoder
label_encoder = LabelEncoder()

# Fit label encoder on the target variable and transform the labels
target_test_encoded = label_encoder.fit_transform(target_test)

# Generate the classification report and plot
scores_xgb = plot_classification_report(target_test_encoded, XGB_model.predict(data_test))



from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.backends.backend_pdf import PdfPages

# Compute the confusion matrix
cm = confusion_matrix(target_test, predictions)

# Define the class labels
labels = ['Adenoma', 'Cancer', 'Normal']

# Plot the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap="Blues", fmt=".0f", xticklabels=labels, yticklabels=labels)
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("True")
pdf_file2 = "confusion_matrix_2.pdf"
with PdfPages(pdf_file2) as pdf:
    pdf.savefig()

# Display the plot
plt.show()

print("Confusion matrix saved as:", pdf_file)


## Descision Tree Model
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn.model_selection import cross_val_score
import time

# Initialize the Decision Tree classifier with specified hyperparameters
tree_model = DecisionTreeClassifier(max_depth=5, min_samples_split=10, criterion='gini')

# Train the model
start = time.time()
tree_model.fit(data_train, target_train)
elapsed_time_2 = time.time() - start

# Predict on the test set
predictions = tree_model.predict(data_test)

# Compute and print accuracy
accuracy = accuracy_score(target_test, predictions)
print(f"Accuracy: {accuracy:.4f}")

# Perform cross-validation
cv_scores = cross_val_score(tree_model, data_train, target_train, cv=5)
print(f"Cross-Validation Scores: {cv_scores}")
print(f"Mean Cross-Validation Score: {cv_scores.mean():.4f}")

print(
    f"The model {tree_model.__class__.__name__} was trained in "
    f"{elapsed_time_2:.3f} seconds"
)


scores_dt =plot_classification_report(target_test, tree_model.predict(data_test))


from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# Generate predictions using the trained model
predictions = tree_model.predict(data_test)

# Compute the confusion matrix
cm = confusion_matrix(target_test, predictions)

# Define the labels for the confusion matrix
labels = ['Adenoma', 'Normal', 'Cancer']

# Plot the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap="Blues", fmt=".0f", xticklabels=labels, yticklabels=labels)
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("True")
pdf_file3 = "confusion_matrix_3.pdf"
with PdfPages(pdf_file3) as pdf:
    pdf.savefig()

# Display the plot
plt.show()

print("Confusion matrix saved as:", pdf_file)



## Results

scores_list = [scores_rf, scores_xgb, scores_dt]
model_list = [ 'RandomForestClassifier','XGBoost', 'DecisionTree']
 

import pandas as pd

metadata_results = pd.DataFrame(columns=['model', 'accuracy', 'precision', 'recall', 'f1 score'])

metadata_results['model'] = model_list
for i, model_scores in enumerate(scores_list):
    if i < len(model_list):
        metadata_results.loc[i, 'accuracy'] = model_scores[0]
        metadata_results.loc[i, 'precision'] = model_scores[1]
        metadata_results.loc[i, 'recall'] = model_scores[2]
        metadata_results.loc[i, 'f1 score'] = model_scores[3]

metadata_results = metadata_results.rename(columns={'accuracy': 'accuray'})


import plotly.figure_factory as ff
import plotly.offline as py


table  = ff.create_table(np.round(metadata_results,4),colorscale=[[0, '#018571'],[.5, '#ffffff'],[1, '#ffffff']],
                        font_colors=['#ffffff', '#000000', '#000000'])

py.iplot(table)

# Calculate SHAP values for all features
explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X_train_array)

# Create a summary plot
shap.summary_plot(shap_values, X_train_array, feature_names=column_names, plot_type='bar', show=False)
plt.title('RandomFrestClassifier')
# Display the plot
plt.show()


mean_abs_shap_values = np.mean(np.abs(shap_values), axis=0)

# Get the indices of the top 20 features based on mean absolute SHAP values
top_20_indices = np.argsort(mean_abs_shap_values)[-20:][::-1]

# Get the corresponding feature names
top_20_features = column_names[top_20_indices]
top_20_features_rf = top_20_features[0]


from sklearn.preprocessing import LabelEncoder
import shap

# Convert the target variable to numeric labels using LabelEncoder
label_encoder = LabelEncoder()
target_train_encoded = label_encoder.fit_transform(target_train)

# Create an XGBoost model
xgb_model = XGBClassifier(random_state=101, booster='gbtree', min_child_weight=23, max_depth=6)

# Fit the model
xgb_model.fit(data_train, target_train_encoded)

# Calculate SHAP values for all features
explainer = shap.TreeExplainer(xgb_model)
shap_values = explainer.shap_values(data_train)

# Create a summary plot
shap.summary_plot(shap_values, data_train, feature_names=column_names, plot_type='bar', show=False)
plt.title('XGBoost Model')
# Display the plot
plt.show()



mean_abs_shap_values = np.mean(np.abs(shap_values), axis=0)

# Get the indices of the top 20 features based on mean absolute SHAP values
top_20_indices = np.argsort(mean_abs_shap_values)[-20:][::-1]

# Get the corresponding feature names
top_20_features = column_names[top_20_indices]
top_20_features_bg = top_20_features[0]

mean_abs_shap_values = np.mean(np.abs(shap_values), axis=0)

# Get the indices of the top 20 features based on mean absolute SHAP values
top_20_indices = np.argsort(mean_abs_shap_values)[-20:][::-1]

# Get the corresponding feature names
top_20_features = column_names[top_20_indices]
top_20_features_xgb = top_20_features[0]

# Convert to numpy array before indexing
top_20_features = np.array(column_names)[top_20_indices]
top_20_features_xgb = top_20_features[0]


## Random Forest after applying feature selection
from sklearn.ensemble import RandomForestClassifier
from sklearn.experimental import enable_halving_search_cv
from sklearn.model_selection import HalvingGridSearchCV

# Grid Search
param_grid = {'max_depth': [3, 5, 10],
              'min_samples_split': [2, 5, 10],
              'n_estimators': [100,200]}

base_estimator = RandomForestClassifier(random_state=0, n_estimators=200)  # Corrected argument passing
sh = HalvingGridSearchCV(base_estimator, param_grid, cv=10, factor=2, min_resources=10, max_resources=60).fit(data_train[top_20_features_rf], target_train)

best_estimator = sh.best_estimator_


scores_rf1 = plot_classification_report(target_test, best_estimator.predict(data_test[top_20_features_rf]))

from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Make predictions using the Random Forest model
predictions = best_estimator.predict(data_test[top_20_features_rf])

# Calculate the confusion matrix
cm = confusion_matrix(target_test, predictions)

# Define the labels for the confusion matrix
labels = ['Adenoma', 'Cancer', 'Normal']

# Plot the confusion matrix using a heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap="Blues", fmt=".0f", xticklabels=labels, yticklabels=labels)
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("True")
pdf_file4 = "confusion_matrix_4.pdf"
with PdfPages(pdf_file4) as pdf:
    pdf.savefig()

# Display the plot
plt.show()

print("Confusion matrix saved as:", pdf_file)



## XGBoost after aplying feature selection
ffrom xgboost import XGBClassifier
from sklearn.model_selection import GridSearchCV

# Define the parameter grid to search over
param_grid = {
    'max_depth': [3, 6, 9],
    'min_child_weight': [1, 5, 10],
    'n_estimators': [100, 200]  # Add the desired number of boosting rounds
}

# Create an instance of the XGBClassifier
xgb_model = XGBClassifier(random_state=101)

# Create a GridSearchCV object
grid_search = GridSearchCV(xgb_model, param_grid, cv=10, scoring='accuracy')

# Fit the GridSearchCV object on the training data
grid_search.fit(data_train[top_20_features_xgb], target_train_encoded)

# Get the best parameter values and the corresponding accuracy score
best_params = grid_search.best_params_
best_score = grid_search.best_score_

# Train the XGBoost model with the best parameters
XGB_model = XGBClassifier(random_state=101, **best_params)
XGB_model.fit(data_train[top_20_features_xgb], target_train_encoded)

print("Best Parameters:", best_params)
print("Best Score:", best_score)


scores_xgb1 =plot_classification_report(target_test,  model.predict(data_test[top_20_features_xgb]))


from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Make predictions using the Random Forest model
predictions = best_estimator.predict(data_test[top_20_features_xgb])

# Calculate the confusion matrix
cm = confusion_matrix(target_test, predictions)

# Define the labels for the confusion matrix
labels = ['Adenoma', 'Cancer', 'Normal']

# Plot the confusion matrix using a heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap="Blues", fmt=".0f", xticklabels=labels, yticklabels=labels)
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("True")
pdf_file4 = "confusion_matrix_4.pdf"
with PdfPages(pdf_file4) as pdf:
    pdf.savefig()

# Display the plot
plt.show()

print("Confusion matrix saved as:", pdf_file)



## Comparison of Random Forest and XGB Models Before and After Feature Selection

scores_list = [ scores_rf, scores_rf1 , scores_xgb, scores_xgb1]
model_list = [  'RF before FS', 'RF after FS' , 'XGB before', 'XGB after' ]


metadata_results = pd.DataFrame(columns=['model', 'accuracy', 'precision', 'recall', 'f1 score'])

metadata_results['model'] = model_list
for i, model_scores in enumerate(scores_list):
    if i < len(model_list):
        metadata_results.loc[i, 'accuracy'] = model_scores[0]
        metadata_results.loc[i, 'precision'] = model_scores[1]
        metadata_results.loc[i, 'recall'] = model_scores[2]
        metadata_results.loc[i, 'f1 score'] = model_scores[3]

metadata_results = metadata_results.rename(columns={'accuracy': 'accuray'})


metadata_results


import plotly.figure_factory as ff
import plotly.offline as py


table  = ff.create_table(np.round(metadata_results,4),colorscale=[[0, '#018571'],[.5, '#ffffff'],[1, '#ffffff']],
                        font_colors=['#ffffff', '#000000', '#000000'])

py.iplot(table)
                
                





















